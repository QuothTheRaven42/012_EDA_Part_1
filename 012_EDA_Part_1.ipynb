{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T22:22:12.060297Z",
     "start_time": "2019-12-21T22:22:12.056965Z"
    }
   },
   "source": [
    "<img src='graphics/titanic.jpg'>\n",
    "\n",
    "# 012 Exploratory Data Analysis (EDA), Part 1\n",
    "\n",
    "In past sessions we have talked about initial data analyses (IDA) briefly, and we described some of the quick commands to learn more about your data. We have also talked about visualizing data with Matplotlib and Seaborn in the previous two meetings. In this notebook, we will bring all of these lessons together to talk about how to explore your data more fully in what is the first important step in data analytics and data science.\n",
    "\n",
    "# What is an EDA?\n",
    "\n",
    "The National Institute of Standards and Technology (NIST) describes an EDA as an approach/philosophy for data analysis that employs a variety of techniques to:\n",
    "1. **maximize** insight into a data set;\n",
    "1. **uncover** underlying structure;\n",
    "1. **extract** important variables;\n",
    "1. **detect** outliers and anomalies;\n",
    "1. **test** underlying assumptions;\n",
    "1. **develop** parsimonious models; and\n",
    "1. **determine** optimal factor settings.\n",
    "\n",
    "While there are multiple ways to approach and code an EDA, there is only three steps in the process.\n",
    "- Explore / Question\n",
    "- Clean / Verify\n",
    "- Document / Save\n",
    "\n",
    "As we have said many times already in our meetings, a common phrase within data analytics and data science is that 80%-90% of a data analysis' or data scientist's job is spent cleaning data (\"data munging\"). And to begin doing that, we have to know the data.\n",
    "\n",
    "___\n",
    "___\n",
    "\n",
    "# The Dataset\n",
    "\n",
    "This is our first introduction to the famous (at least within the data munging) Titanic Dataset. \n",
    "\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n",
    "\n",
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n",
    "\n",
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n",
    "\n",
    "This dataset consists of the manifest of the Titanic passengers on that fateful voyage. The dataset is split into two sub-sets:\n",
    "- train.csv\n",
    "- test.csv\n",
    "\n",
    "The training set is used to build your machine learning models, which we will do in later meetings. For the training set, the outcome (also known as the “ground truth”) for each passenger is provided. Our later predictive machine learning model will be based on “features” like passengers’ gender and class. \n",
    "\n",
    "The test set is used to see how well our yet to be built machine learning model performs on unseen data. For the test set, the ground truth for each passenger is not provided. In a later meeting, it will be our job to predict these outcomes. \n",
    "\n",
    "\n",
    "## Data Dictionary\n",
    "- 1survival: Survival- 0 = No, 1 = Yes\n",
    "- pclass: Ticket class- 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "- sex: Gender\t\n",
    "- Age: The ticket holder's age in years\t\n",
    "- sibsp: # of siblings / spouses aboard the Titanic with the ticket holder\t\n",
    "- parch: # of parents / children aboard the Titanic with the ticket holder\t\n",
    "- ticket: Ticket number\t\n",
    "- fare: Passenger fare\t\n",
    "- cabin: Cabin number\t\n",
    "- embarked:Port of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "### Variable Notes\n",
    "pclass: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "sibsp: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "\n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "parch: The dataset defines family relations in this way...\n",
    "\n",
    "Parent = mother, father\n",
    "\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "\n",
    "Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "\n",
    "___ \n",
    "\n",
    "# Step 1 - Explore and Question the Data\n",
    "\n",
    "## Step 1a - Loading the data\n",
    "\n",
    "To begin, we need to load the data into a Pandas DataFrame. In the next block,\n",
    "1. Load the Pandas Library\n",
    "1. Load the Matplotlib.pyplot library for later\n",
    "1. Load the train.csv dataset\n",
    "1. Check the first five rows of the DataFrame to get our first look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:52.872835Z",
     "start_time": "2019-12-22T12:59:52.361996Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1b - Questioning the Data\n",
    "\n",
    "Next, with the raw data, we begin to question the data. \n",
    "\n",
    "### Question 1: How large is the dataset?\n",
    "\n",
    "Using what you have learned, write the code to find out how large is the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:52.877856Z",
     "start_time": "2019-12-22T12:59:52.874338Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: What types of variables are in the dataset?\n",
    "\n",
    "Using what you have learned, write the code to find out what types of variables are in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:52.885719Z",
     "start_time": "2019-12-22T12:59:52.879569Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examination Notes\n",
    "As we look at the types of variables, is there anything that stands out which we may want to take note of and address later in our cleaning?\n",
    "\n",
    "___\n",
    "\n",
    "### Question 3: Are there any missing values in the dataset?\n",
    "\n",
    "Missing values are important to know as it will affect our later analyses. There are a number of ways to address missing values when we later build our predictive machine learning model, but for now - as this is an *EXPLORATORY* data analysis - we are focused only on exploring the data. We will clean it in the next step.\n",
    "\n",
    "#### Method 1: `.info( )`\n",
    "\n",
    "The first method, which we have already covered, is the `.info( )` method. Since you already know this method, go ahead and code this method. Using what you have learned, go ahead and code the next line yourself, then run it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:52.893838Z",
     "start_time": "2019-12-22T12:59:52.887591Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: `isnull( ).sum( )`\n",
    "\n",
    "To find missing values in a dataset, we use the `.isnull()` command, and since we will want the total of any missing values by column, we will want to add `.sum()` on to that command.\n",
    "\n",
    "Because we did not cover this command before, I took the liberty of coding it for you. Run the next line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:52.900674Z",
     "start_time": "2019-12-22T12:59:52.895361Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus Challenge\n",
    "\n",
    "Reaching back to our discussions on graphing, write the code to graph the sum of nulls in Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:53.171419Z",
     "start_time": "2019-12-22T12:59:52.902734Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examination Notes \n",
    "Do we see anything that we will want to note about missing values as we get to the next or subsequent phases?\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "### Question 4: Are there any duplicated rows in the dataset?\n",
    "\n",
    "As we might suspect, duplicated observations/rows will throw our later anlaysis off. In order to find the count of duplicated values, we want to use the `.duplicated()` command. And again, since we want to look at a count of the number of duplications within the dataset we will want to add the `.sum()` command to our code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:53.179428Z",
     "start_time": "2019-12-22T12:59:53.172553Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: What is the statistical description say about the dataset?\n",
    "\n",
    "Given our past discussions, use the appropriate command to show the statistical description of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:53.209362Z",
     "start_time": "2019-12-22T12:59:53.181600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "We have done a number of things already to explore and question our data. In order to make it easier to picture in our heads, in the next block write out code to do Step 1 so that it is in one block of code (answering the four questions we asked in Step 1). \n",
    "\n",
    "### Extra Challenge\n",
    "Can you write this in one line of code, giving each element a title, and separating the output by a blank space so it is easier to read?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:53.241244Z",
     "start_time": "2019-12-22T12:59:53.211607Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Clean and Verify the Data\n",
    "\n",
    "Now that we have done an initial look at the data, we know that there is some cleaning to do. Looking back at our notes from Step 1, we know that some of the variable types need to be changed. \n",
    "1. Let's discuss each variable before we change them. \n",
    "1. Then we will change each variable type to what we need them to be. \n",
    "\n",
    ">### A note on EDA intended output\n",
    ">Not every problem is the same, so not every EDA exercise will be either. Beyond the basic quality and cleanliness of your dataset (as Omar Elgabry states), “Understanding what are you trying to accomplish, your ultimate goal is critical prior to taking any actions.”. A clear understanding of the purpose and intended use case for your final dataset will inform any additional EDA tasks you may wish to perform.\n",
    "\n",
    ">For example, if your goal is to run your data through a machine learning algorithm to solve a binary classification problem (i.e. predict an outcome of yes/no, is likely/not likely, etc.), you’ll need to perform some type of “preprocessing” on your target (predictor) variable to assign binary values to your positive (1) and negative (0) classes. If your data includes “categorical” data types, you’ll need to convert them to numerical values prior to machine learning. A common pandas method to accomplish this is:\n",
    ">`.get_dummies()` — convert categorical variables [https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html]\n",
    "\n",
    "## Integer, Float or Object?\n",
    "How many of our variable types are integers or floats which will be used as text or \"objects\"?\n",
    "\n",
    "In the next block, using what we have already learned from our meetings about Pandas, change the variables appropriately from our discussion for this dataset. Then verify that the changes have taken place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:53.249550Z",
     "start_time": "2019-12-22T12:59:53.242906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about Column Titles?\n",
    "\n",
    "This step is purely optional, but we will do it anyway so that we have nice and clean column titles. \n",
    "\n",
    "When we talked about Pandas previously, we discussed on method of changing column titles by listing them out in a dictionary and changing the titles. While that method is fine for the dataset we used at the time (and could be used for this dataset given its limited number of columns), what happens when you have 25 feature names? 75? 1000?\n",
    "\n",
    "Another simple method to changing all of the feature names to columns is to use the `map()` command - which maps back to the DataFrame what you want to change. In addition, we want to use the `.lower()` command which changes all of the strings that you designate to all lower case. \n",
    "\n",
    "I took the liberty of writing out this code so you can see how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:53.264610Z",
     "start_time": "2019-12-22T12:59:53.250947Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map the lowering function to all column names\n",
    "df.columns = map(str.lower, df.columns)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Verify and Explore the Data a Bit More\n",
    "\n",
    "Now that we have cleaned our data, let's do a bit more exploring by way of separating and plotting the values.\n",
    "\n",
    "### Separating the columns into numeric & categorical\n",
    "\n",
    "Having a list of the numeric columns and a list of the categorical columns comes in handy for plotting and for working with each category. In the next block, write a block of code that examines each column and separates it into a numeric column (num_column) list or into a categorical column (cat_column) list. Then print out each list with a title to the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:53.272286Z",
     "start_time": "2019-12-22T12:59:53.266006Z"
    }
   },
   "outputs": [],
   "source": [
    "#Write your code here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So why do we want to lists of column types?\n",
    "\n",
    "In the next block of code you will see that by having a list of all of the numerical column names, we can produce multiple charts with one simple line of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:54.140760Z",
     "start_time": "2019-12-22T12:59:53.273803Z"
    }
   },
   "outputs": [],
   "source": [
    "#This will turn off any warnings from running the next bit of code.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#We set the figure size.\n",
    "plt.figure(figsize = (15,15))\n",
    "\n",
    "#This allows you to retrieve the axis in the figure we will create\n",
    "# so that we can print two charts side by side. \n",
    "# It is needed in the next line of code.\n",
    "ax = plt.gca()\n",
    "\n",
    "#This plots each of the numerical columns on a separate histogram\n",
    "# with two histograms per row.\n",
    "df[num_column].hist(ax=ax)\n",
    "\n",
    "# And this shows the graphs.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pclass & survived\n",
    "\n",
    "Using the seaborn library, select an appropriate plot to examine the relationship between pclass and survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:54.590211Z",
     "start_time": "2019-12-22T12:59:54.142504Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sex & survived\n",
    "\n",
    "Using the seaborn library, select an appropriate plot to examine the relationship between sex and survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:54.791513Z",
     "start_time": "2019-12-22T12:59:54.592097Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### age & survived\n",
    "\n",
    "Using the seaborn library, select an appropriate plot to examine the relationship between age and survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:54.928287Z",
     "start_time": "2019-12-22T12:59:54.793132Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parch & survived\n",
    "\n",
    "Using the seaborn library, select an appropriate plot to examine the relationship between parch and survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:55.122487Z",
     "start_time": "2019-12-22T12:59:54.929731Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embark & survived\n",
    "\n",
    "Using the seaborn library, select an appropriate plot to examine the relationship between embarked and survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:55.373263Z",
     "start_time": "2019-12-22T12:59:55.123731Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sibsp & survived\n",
    "\n",
    "Using the seaborn library, select an appropriate plot to examine the relationship between sibsp and survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:55.509220Z",
     "start_time": "2019-12-22T12:59:55.374588Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fare & pclass & survived\n",
    "\n",
    "Using the seaborn library, select an appropriate plot to examine the relationship between fare, pclass, and survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:55.723537Z",
     "start_time": "2019-12-22T12:59:55.510350Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sex & pclass & survived\n",
    "\n",
    "Using the seaborn library, select an appropriate plot to examine the relationship between sex, pclass, and survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:55.915621Z",
     "start_time": "2019-12-22T12:59:55.725262Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sex & age & survived\n",
    "\n",
    "Using the seaborn library, select an appropriate plot to examine the relationship between sex, age, and survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T12:59:56.176094Z",
     "start_time": "2019-12-22T12:59:55.917378Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sex & parch & survived\n",
    "\n",
    "Using the seaborn library, select an appropriate plot to examine the relationship between sex, parch, and survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T13:00:03.635885Z",
     "start_time": "2019-12-22T12:59:56.179093Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### age & pclass & survived\n",
    "\n",
    "Using the seaborn library, select an appropriate plot to examine the relationship between age, pclass, and survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T13:00:03.980954Z",
     "start_time": "2019-12-22T13:00:03.637940Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T13:00:04.533778Z",
     "start_time": "2019-12-22T13:00:03.982298Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write your code here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Lesson Item: crosstab\n",
    "\n",
    "For color selections, go to [https://matplotlib.org/3.1.1/tutorials/colors/colormaps.html#sphx-glr-tutorials-colors-colormaps-py]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T13:00:04.863215Z",
     "start_time": "2019-12-22T13:00:04.535161Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab([df.sex, df.survived], df.pclass, margins=True).style.background_gradient(cmap='plasma_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-22T13:00:05.021846Z",
     "start_time": "2019-12-22T13:00:04.864420Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab([df.sibsp, df.survived], df.pclass, margins=True).style.background_gradient(cmap='magma_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "435px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
